//Add data into HDFS
ephemeral-hdfs/bin/hadoop fs -put ~/spark/README.md /user/root/read.md

//In Spark Shell:
//word Count
val data = sc.textFile("read.md")
val wc = data.flatMap(line => line.split(' ')).map(word => (word,1)).cache()
wc.reduceByKey(_+_).collect().foreach(println)


//For decision Tree
Set the datainput file: (decision.txt) # it is equal to 
ephemeral-hdfs/bin/hadoop fs -put ~/decision.txt /user/root/decision.txt
