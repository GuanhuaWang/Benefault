16/04/19 09:38:03 INFO spark.SparkContext: Running Spark version 1.6.0-SNAPSHOT with piping shuffle. Created by pipeshuffle
16/04/19 09:38:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/04/19 09:38:04 WARN spark.SparkConf: 
SPARK_WORKER_INSTANCES was detected (set to '1').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --num-executors to specify the number of executors
 - Or set SPARK_EXECUTOR_INSTANCES
 - spark.executor.instances to configure the number of instances in the spark config.
        
16/04/19 09:38:04 INFO spark.SecurityManager: Changing view acls to: root
16/04/19 09:38:04 INFO spark.SecurityManager: Changing modify acls to: root
16/04/19 09:38:04 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/04/19 09:38:05 INFO util.Utils: Successfully started service 'NettyRpcEnv' on port 0.
16/04/19 09:38:05 INFO slf4j.Slf4jLogger: Slf4jLogger started
16/04/19 09:38:05 INFO Remoting: Starting remoting
16/04/19 09:38:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.31.4.72:49374]
16/04/19 09:38:06 INFO util.Utils: Successfully started service 'sparkDriver' on port 49374.
16/04/19 09:38:06 INFO spark.SparkEnv: Registering MapOutputTracker
16/04/19 09:38:06 INFO spark.SparkEnv: Registering BlockManagerMaster
16/04/19 09:38:06 INFO storage.DiskBlockManager: Created local directory at /mnt/spark/blockmgr-e00e35d1-cfb4-4c75-b605-2fff57acd047
16/04/19 09:38:06 INFO storage.DiskBlockManager: Created local directory at /mnt2/spark/blockmgr-f5e5d944-234b-49f0-a99b-a34037a0a067
16/04/19 09:38:06 INFO storage.MemoryStore: MemoryStore started with capacity 736.5 MB
16/04/19 09:38:06 INFO spark.HttpFileServer: HTTP File server directory is /mnt/spark/spark-bff67f1a-2cb0-462c-8879-c169b76451b5/httpd-2f08c070-3ef3-43dc-9462-59e791ef0913
16/04/19 09:38:06 INFO spark.HttpServer: Starting HTTP Server
16/04/19 09:38:06 INFO server.Server: jetty-8.y.z-SNAPSHOT
16/04/19 09:38:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34368
16/04/19 09:38:06 INFO util.Utils: Successfully started service 'HTTP file server' on port 34368.
16/04/19 09:38:06 INFO spark.SparkEnv: Registering OutputCommitCoordinator
16/04/19 09:38:06 INFO server.Server: jetty-8.y.z-SNAPSHOT
16/04/19 09:38:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/04/19 09:38:06 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
16/04/19 09:38:06 INFO ui.SparkUI: Started SparkUI at http://ec2-54-215-137-117.us-west-1.compute.amazonaws.com:4040
16/04/19 09:38:07 INFO spark.SparkContext: Added JAR file:/root/spark/examples/target/scala-2.10/spark-examples-1.6.0-SNAPSHOT-hadoop2.4.0.jar at http://172.31.4.72:34368/jars/spark-examples-1.6.0-SNAPSHOT-hadoop2.4.0.jar with timestamp 1461058687531
16/04/19 09:38:07 WARN metrics.MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/04/19 09:38:07 INFO client.AppClient$ClientEndpoint: Connecting to master spark://ec2-54-215-137-117.us-west-1.compute.amazonaws.com:7077...
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20160419093807-0021
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/1 on worker-20160419062826-172.31.14.171-49654 (172.31.14.171:49654) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/1 on hostPort 172.31.14.171:49654 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/0 on worker-20160419062826-172.31.14.170-39496 (172.31.14.170:39496) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/0 on hostPort 172.31.14.170:39496 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/4 on worker-20160419062826-172.31.14.162-45469 (172.31.14.162:45469) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/4 on hostPort 172.31.14.162:45469 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52948.
16/04/19 09:38:08 INFO netty.NettyBlockTransferService: Server created on 52948
16/04/19 09:38:08 INFO storage.BlockManagerMaster: Trying to register BlockManager
16/04/19 09:38:08 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.4.72:52948 with 736.5 MB RAM, BlockManagerId(driver, 172.31.4.72, 52948)
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/3 on worker-20160419062826-172.31.14.156-40729 (172.31.14.156:40729) with 2 cores
16/04/19 09:38:08 INFO storage.BlockManagerMaster: Registered BlockManager
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/3 on hostPort 172.31.14.156:40729 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/2 on worker-20160419062826-172.31.14.164-49757 (172.31.14.164:49757) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/2 on hostPort 172.31.14.164:49757 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/5 on worker-20160419062826-172.31.14.155-33901 (172.31.14.155:33901) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/5 on hostPort 172.31.14.155:33901 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/7 on worker-20160419062826-172.31.14.168-57638 (172.31.14.168:57638) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/7 on hostPort 172.31.14.168:57638 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/8 on worker-20160419062826-172.31.14.169-53143 (172.31.14.169:53143) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/8 on hostPort 172.31.14.169:53143 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/6 on worker-20160419062826-172.31.14.160-55081 (172.31.14.160:55081) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/6 on hostPort 172.31.14.160:55081 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/11 on worker-20160419062826-172.31.14.154-55350 (172.31.14.154:55350) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/11 on hostPort 172.31.14.154:55350 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/12 on worker-20160419062826-172.31.14.158-50877 (172.31.14.158:50877) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/12 on hostPort 172.31.14.158:50877 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/10 on worker-20160419062826-172.31.14.157-56581 (172.31.14.157:56581) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/10 on hostPort 172.31.14.157:56581 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/9 on worker-20160419062826-172.31.14.153-53751 (172.31.14.153:53751) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/9 on hostPort 172.31.14.153:53751 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/14 on worker-20160419062826-172.31.14.159-46219 (172.31.14.159:46219) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/14 on hostPort 172.31.14.159:46219 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/15 on worker-20160419062826-172.31.14.161-36155 (172.31.14.161:36155) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/15 on hostPort 172.31.14.161:36155 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/13 on worker-20160419062826-172.31.14.165-48351 (172.31.14.165:48351) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/13 on hostPort 172.31.14.165:48351 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/17 on worker-20160419062826-172.31.14.172-38171 (172.31.14.172:38171) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/17 on hostPort 172.31.14.172:38171 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/3 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/6 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/18 on worker-20160419062826-172.31.14.166-35330 (172.31.14.166:35330) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/18 on hostPort 172.31.14.166:35330 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor added: app-20160419093807-0021/16 on worker-20160419062826-172.31.14.167-56371 (172.31.14.167:56371) with 2 cores
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160419093807-0021/16 on hostPort 172.31.14.167:56371 with 2 cores, 6.0 GB RAM
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/4 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/15 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/0 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/11 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/1 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/2 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/18 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/9 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/7 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/14 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/8 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/12 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/5 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/13 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/17 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/10 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/16 is now LOADING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/1 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/0 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/4 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/3 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/5 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/2 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/7 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/8 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/11 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/6 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/12 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/10 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/9 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/14 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/15 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/13 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/17 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/18 is now RUNNING
16/04/19 09:38:08 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160419093807-0021/16 is now RUNNING
16/04/19 09:38:08 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; size: 0
16/04/19 09:38:09 INFO spark.SparkContext: Starting job: count at GroupByTest.scala:50
16/04/19 09:38:09 INFO scheduler.DAGScheduler: pipeshuffle: It's a pipeShuffle version
16/04/19 09:38:09 INFO scheduler.DAGScheduler: Got job 0 (count at GroupByTest.scala:50) with 20 output partitions
16/04/19 09:38:09 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at GroupByTest.scala:50)
16/04/19 09:38:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
16/04/19 09:38:09 INFO scheduler.DAGScheduler: Missing parents: List()
16/04/19 09:38:09 INFO scheduler.DAGScheduler: pipeshuffle: Stage 0 doesn't have  pending shuffle
16/04/19 09:38:09 INFO storage.MemoryStore: Ensuring 1048576 bytes of free space for block broadcast_0(free: 772276224, max: 772276224)
16/04/19 09:38:09 INFO storage.MemoryStore: Ensuring 1992 bytes of free space for block broadcast_0(free: 772276224, max: 772276224)
16/04/19 09:38:09 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1992.0 B, free 1992.0 B)
16/04/19 09:38:09 INFO storage.MemoryStore: Ensuring 1329 bytes of free space for block broadcast_0_piece0(free: 772274232, max: 772276224)
16/04/19 09:38:09 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1329.0 B, free 3.2 KB)
16/04/19 09:38:09 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.4.72:52948 (size: 1329.0 B, free: 736.5 MB)
16/04/19 09:38:09 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1234
16/04/19 09:38:09 INFO scheduler.DAGScheduler: Submitting 20 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at flatMap at GroupByTest.scala:39)
16/04/19 09:38:09 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 20 tasks of stage 0
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.156:58453) with ID 3
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.31.14.156, partition 0,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.156:60151 with 4.3 GB RAM, BlockManagerId(3, 172.31.14.156, 60151)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.31.14.156, partition 1,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.169:37195) with ID 8
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 172.31.14.169, partition 2,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 172.31.14.169, partition 3,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.165:59182) with ID 13
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 172.31.14.165, partition 4,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 172.31.14.165, partition 5,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.168:42240) with ID 7
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 172.31.14.168, partition 6,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 172.31.14.168, partition 7,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.159:34665) with ID 14
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 172.31.14.159, partition 8,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 172.31.14.159, partition 9,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.160:42854) with ID 6
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.165:37384 with 4.3 GB RAM, BlockManagerId(13, 172.31.14.165, 37384)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.169:34799 with 4.3 GB RAM, BlockManagerId(8, 172.31.14.169, 34799)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 172.31.14.160, partition 10,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 172.31.14.160, partition 11,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.172:51569) with ID 17
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 172.31.14.172, partition 12,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.159:41682 with 4.3 GB RAM, BlockManagerId(14, 172.31.14.159, 41682)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 172.31.14.172, partition 13,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.166:57415) with ID 18
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 172.31.14.166, partition 14,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 172.31.14.166, partition 15,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.170:41998) with ID 0
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 172.31.14.170, partition 16,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 172.31.14.170, partition 17,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.154:52801) with ID 11
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.160:51857 with 4.3 GB RAM, BlockManagerId(6, 172.31.14.160, 51857)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 172.31.14.154, partition 18,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 172.31.14.154, partition 19,PROCESS_LOCAL, 2170 bytes, speculative: false)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.168:35473 with 4.3 GB RAM, BlockManagerId(7, 172.31.14.168, 35473)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.161:40059) with ID 15
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.172:38815 with 4.3 GB RAM, BlockManagerId(17, 172.31.14.172, 38815)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.155:36212) with ID 5
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.162:48631) with ID 4
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.153:40921) with ID 9
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.158:51608) with ID 12
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.171:37197) with ID 1
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.164:33834) with ID 2
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.166:58926 with 4.3 GB RAM, BlockManagerId(18, 172.31.14.166, 58926)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.161:53004 with 4.3 GB RAM, BlockManagerId(15, 172.31.14.161, 53004)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.154:46752 with 4.3 GB RAM, BlockManagerId(11, 172.31.14.154, 46752)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.155:38538 with 4.3 GB RAM, BlockManagerId(5, 172.31.14.155, 38538)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.170:43274 with 4.3 GB RAM, BlockManagerId(0, 172.31.14.170, 43274)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.162:34092 with 4.3 GB RAM, BlockManagerId(4, 172.31.14.162, 34092)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.157:45722) with ID 10
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.158:43454 with 4.3 GB RAM, BlockManagerId(12, 172.31.14.158, 43454)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.171:38100 with 4.3 GB RAM, BlockManagerId(1, 172.31.14.171, 38100)
16/04/19 09:38:12 INFO cluster.SparkDeploySchedulerBackend: Registered executor: NettyRpcEndpointRef(spark://Executor@172.31.14.167:54230) with ID 16
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.153:52731 with 4.3 GB RAM, BlockManagerId(9, 172.31.14.153, 52731)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.164:48569 with 4.3 GB RAM, BlockManagerId(2, 172.31.14.164, 48569)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.157:47532 with 4.3 GB RAM, BlockManagerId(10, 172.31.14.157, 47532)
16/04/19 09:38:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.31.14.167:43649 with 4.3 GB RAM, BlockManagerId(16, 172.31.14.167, 43649)
16/04/19 09:38:19 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.168:35473 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:19 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.172:38815 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:21 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.156:60151 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:22 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.165:37384 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:23 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.169:34799 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:24 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.160:51857 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:24 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.166:58926 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:24 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.154:46752 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:24 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.159:41682 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:25 INFO storage.BlockManagerInfo: Added rdd_1_7 in memory on 172.31.14.168:35473 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:25 INFO storage.BlockManagerInfo: Added rdd_1_6 in memory on 172.31.14.168:35473 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:25 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 12757 ms on 172.31.14.168 (1/20)
16/04/19 09:38:25 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 12769 ms on 172.31.14.168 (2/20)
16/04/19 09:38:25 INFO storage.BlockManagerInfo: Added rdd_1_13 in memory on 172.31.14.172:38815 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:25 INFO storage.BlockManagerInfo: Added rdd_1_12 in memory on 172.31.14.172:38815 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:25 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 13124 ms on 172.31.14.172 (3/20)
16/04/19 09:38:25 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 13132 ms on 172.31.14.172 (4/20)
16/04/19 09:38:25 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.31.14.170:43274 (size: 1329.0 B, free: 4.3 GB)
16/04/19 09:38:27 INFO storage.BlockManagerInfo: Added rdd_1_0 in memory on 172.31.14.156:60151 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14850 ms on 172.31.14.156 (5/20)
16/04/19 09:38:27 INFO storage.BlockManagerInfo: Added rdd_1_1 in memory on 172.31.14.156:60151 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:27 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14820 ms on 172.31.14.156 (6/20)
16/04/19 09:38:29 INFO storage.BlockManagerInfo: Added rdd_1_5 in memory on 172.31.14.165:37384 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:29 INFO storage.BlockManagerInfo: Added rdd_1_4 in memory on 172.31.14.165:37384 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:29 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 16646 ms on 172.31.14.165 (7/20)
16/04/19 09:38:29 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 16650 ms on 172.31.14.165 (8/20)
16/04/19 09:38:29 INFO storage.BlockManagerInfo: Added rdd_1_2 in memory on 172.31.14.169:34799 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:29 INFO storage.BlockManagerInfo: Added rdd_1_3 in memory on 172.31.14.169:34799 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:29 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 17440 ms on 172.31.14.169 (9/20)
16/04/19 09:38:29 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 17444 ms on 172.31.14.169 (10/20)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_11 in memory on 172.31.14.160:51857 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_10 in memory on 172.31.14.160:51857 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 17655 ms on 172.31.14.160 (11/20)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 17649 ms on 172.31.14.160 (12/20)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_15 in memory on 172.31.14.166:58926 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_14 in memory on 172.31.14.166:58926 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 17991 ms on 172.31.14.166 (13/20)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 17995 ms on 172.31.14.166 (14/20)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_19 in memory on 172.31.14.154:46752 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_18 in memory on 172.31.14.154:46752 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 18040 ms on 172.31.14.154 (15/20)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 18036 ms on 172.31.14.154 (16/20)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_9 in memory on 172.31.14.159:41682 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:30 INFO storage.BlockManagerInfo: Added rdd_1_8 in memory on 172.31.14.159:41682 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 18319 ms on 172.31.14.159 (17/20)
16/04/19 09:38:30 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 18325 ms on 172.31.14.159 (18/20)
16/04/19 09:38:31 INFO storage.BlockManagerInfo: Added rdd_1_16 in memory on 172.31.14.170:43274 (size: 573.9 MB, free: 3.8 GB)
16/04/19 09:38:31 INFO storage.BlockManagerInfo: Added rdd_1_17 in memory on 172.31.14.170:43274 (size: 573.9 MB, free: 3.2 GB)
16/04/19 09:38:31 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 19083 ms on 172.31.14.170 (19/20)
16/04/19 09:38:31 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 19086 ms on 172.31.14.170 (20/20)
16/04/19 09:38:31 INFO scheduler.DAGScheduler: ResultStage 0 (count at GroupByTest.scala:50) finished in 22.191 s
16/04/19 09:38:31 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Job 0 finished: count at GroupByTest.scala:50, took 22.528799 s
16/04/19 09:38:31 INFO spark.SparkContext: Starting job: count at GroupByTest.scala:52
16/04/19 09:38:31 INFO scheduler.DAGScheduler: pipeshuffle: It's a pipeShuffle version
16/04/19 09:38:31 INFO scheduler.DAGScheduler: pipeshuffle: It's a pipeShuffle version
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Registering RDD 1 (flatMap at GroupByTest.scala:39)
16/04/19 09:38:31 INFO spark.MapOutputTrackerMaster: pipeshuffle: register shuffle 0 with statuses 20
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Got job 1 (count at GroupByTest.scala:52) with 20 output partitions
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at GroupByTest.scala:52)
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
16/04/19 09:38:31 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.4.72:52948 in memory (size: 1329.0 B, free: 736.5 MB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.165:37384 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.160:51857 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.172:38815 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.170:43274 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.166:58926 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.169:34799 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.154:46752 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.159:41682 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.156:60151 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.31.14.168:35473 in memory (size: 1329.0 B, free: 3.2 GB)
16/04/19 09:42:44 INFO spark.ContextCleaner: Cleaned accumulator 1
16/04/19 09:54:52 INFO spark.SparkContext: Invoking stop() from shutdown hook
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
16/04/19 09:54:52 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
16/04/19 09:54:52 INFO ui.SparkUI: Stopped Spark web UI at http://ec2-54-215-137-117.us-west-1.compute.amazonaws.com:4040
16/04/19 09:54:52 INFO scheduler.DAGScheduler: Stopping DAGScheduler
16/04/19 09:54:52 INFO scheduler.DAGScheduler: Job 1 failed: count at GroupByTest.scala:52, took 980.722574 s
16/04/19 09:54:52 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (flatMap at GroupByTest.scala:39) failed in Unknown s
Exception in thread "main" org.apache.spark.SparkException: Job cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:931)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1925)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1846)
	at org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1720)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1196)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1719)
	at org.apache.spark.SparkContext$$anonfun$3.apply$mcV$sp(SparkContext.scala:579)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:266)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:236)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:236)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:236)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1708)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:236)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:236)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:236)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:236)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:216)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:746)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1820)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1833)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1846)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1917)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1119)
	at org.apache.spark.examples.GroupByTest$.main(GroupByTest.scala:52)
	at org.apache.spark.examples.GroupByTest.main(GroupByTest.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:680)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
16/04/19 09:54:52 INFO cluster.SparkDeploySchedulerBackend: Shutting down all executors
16/04/19 09:54:52 INFO cluster.SparkDeploySchedulerBackend: Asking each executor to shut down
16/04/19 09:54:52 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/04/19 09:54:52 INFO storage.MemoryStore: MemoryStore cleared
16/04/19 09:54:52 INFO storage.BlockManager: BlockManager stopped
16/04/19 09:54:52 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
16/04/19 09:54:52 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/04/19 09:54:52 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/04/19 09:54:52 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/04/19 09:54:52 INFO spark.SparkContext: Successfully stopped SparkContext
16/04/19 09:54:52 INFO util.ShutdownHookManager: Shutdown hook called
16/04/19 09:54:52 INFO util.ShutdownHookManager: Deleting directory /mnt2/spark/spark-875fd64e-d526-410e-aeca-e92a75922400
16/04/19 09:54:52 INFO util.ShutdownHookManager: Deleting directory /mnt/spark/spark-bff67f1a-2cb0-462c-8879-c169b76451b5
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
Killed by signal 15.
